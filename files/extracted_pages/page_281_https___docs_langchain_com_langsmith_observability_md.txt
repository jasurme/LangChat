Published Time: Thu, 12 Feb 2026 09:06:03 GMT

> ## Documentation Index
> Fetch the complete documentation index at: https://docs.langchain.com/llms.txt
> Use this file to discover all available pages before exploring further.

# LangSmith Observability

The following sections help you set up and use tracing, monitoring, and observability features:

 LangSmith works with many frameworks and providers. Browse [available integrations](/langsmith/integrations) to connect your stack including OpenAI, Anthropic, CrewAI, Vercel AI SDK, Pydantic AI, and more. 

  Configure tracing with basic options, framework integrations, or advanced settings for full control.   Access and manage traces via UI or API with filtering, exporting, sharing, and comparison tools.   Create dashboards and set alerts to track performance and get notified when issues arise.   Use rules, webhooks, and online evaluations to streamline observability workflows.   Gather and manage annotations on outputs using queues and inline annotation.   Follow a step-by-step tutorial to trace a Retrieval-Augmented Generation application from start to finish. 

For terminology definitions and core concepts, refer to [Observability concepts](/langsmith/observability-concepts).

 Use **[Polly](/langsmith/polly)**, LangSmith's AI assistant, to analyze traces and get AI-powered insights into your application's performance. 

 To set up a LangSmith instance, visit the [Platform setup section](/langsmith/platform-setup) to choose between cloud, hybrid, or self-hosted. All options include observability, evaluation, prompt engineering, and deployment. 

***

 [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/observability.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose). 

 [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
