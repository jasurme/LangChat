Published Time: Thu, 12 Feb 2026 11:55:15 GMT

> ## Documentation Index
> Fetch the complete documentation index at: https://docs.langchain.com/llms.txt
> Use this file to discover all available pages before exploring further.

# Cache integrations

> Integrate with caches using LangChain JavaScript.

[Caching LLM calls](/oss/javascript/langchain/models#caching) can be useful for testing, cost savings, and speed.

Below are some integrations that allow you to cache results of individual LLM calls using different caches with different strategies.

 

***

 [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/llm_caching/index.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose). 

 [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
